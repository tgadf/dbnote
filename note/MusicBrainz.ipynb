{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FileIO, CSVIO, PickleIO\n",
    "from utils import DirInfo, FileInfo\n",
    "from utils import Timestat\n",
    "from pandas import read_csv, DataFrame, Series, to_datetime, NaT, isna, concat, merge\n",
    "from numpy import nan\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "def loadData(ifile):\n",
    "    mbdata = cio.get(ifile, delimiter=\"\\t\", header=None, on_bad_lines='skip')\n",
    "    #mbdata = read_csv(ifile, delimiter=\"\\t\", header=None)\n",
    "    mbdata = mbdata.replace('\\\\N', nan)\n",
    "    return mbdata\n",
    "\n",
    "\n",
    "def getData(files, colnames):\n",
    "    data  = {FileInfo(ifile).basename: loadData(ifile) for ifile in files}\n",
    "    print(\"Keys: {0}\".format(data.keys()))\n",
    "    data = {key: val[list(colnames[key].keys())].rename(columns=colnames[key]) for key,val in data.items() if key in colnames} if colnames is not None else data\n",
    "    print(\"Keys: {0}\".format(data.keys()))\n",
    "    return data\n",
    "\n",
    "\n",
    "def setIndex(data):\n",
    "    for key,df in data.items():\n",
    "        colname = df.columns[0]\n",
    "        df.index = df[colname]\n",
    "        df.drop([colname], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def createDate(year, month, day):\n",
    "    if all([isinstance(x,str) for x in [year,month,day]]):\n",
    "        return to_datetime('{0}-{1}-{2}'.format(year, month, day), format='%Y-%m-%d', errors='ignore')\n",
    "    elif all([isinstance(x,str) for x in [year,month]]):\n",
    "        return to_datetime('{0}-{1}'.format(year, month), format='%Y-%m', errors='ignore')\n",
    "    elif all([isinstance(x,str) for x in [year]]):\n",
    "        return to_datetime('{0}'.format(year), format='%Y', errors='ignore')\n",
    "    return NaT\n",
    "\n",
    "\n",
    "def convertToDatetime(year, month, day):\n",
    "    year  = year.apply(lambda x: int(x) if (not isna(x) and x.isdigit()) else -1)\n",
    "    month = month.apply(lambda x: int(x) if (not isna(x) and x.isdigit()) else -1)\n",
    "    day   = day.apply(lambda x: int(x) if (not isna(x) and x.isdigit()) else -1)\n",
    "    tmp   = DataFrame(year).join(month).join(day)\n",
    "    tmp.columns = [\"year\", \"month\", \"day\"]\n",
    "    return to_datetime(tmp, errors='coerce')\n",
    "\n",
    "\n",
    "cio = CSVIO()\n",
    "pio = PickleIO()\n",
    "io  = FileIO()\n",
    "\n",
    "basedir = \"./\"\n",
    "basedir = DirInfo(\"/Volumes/Seagate/DB\")\n",
    "saveDir = DirInfo(basedir.join(\"MusicBrainzData\"))\n",
    "lookDir = DirInfo(saveDir.join(\"lookup\"))\n",
    "dumpDir = DirInfo(basedir.join(\"mbdump\"))\n",
    "\n",
    "aIDs={\"ArianaGrande\": 823336, \"BuddyHolly\": 10937, \"Rupaul\": 34318, \"U2\": 197, \"DMB\": 502, \"Bono\": 35575, \"Mozart\": 11285, \"JohnMayer\": 33563}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s '/Volumes/Seagate/DB/mbdump'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lengthData = open(\"flength.csv\").readlines()\n",
    "lengthData = [x.replace(\"\\n\", \"\").strip().split() for x in lengthData]\n",
    "lengthData = Series({item[1].split(\"/\")[1]: int(item[0]) for item in lengthData if len(item[1].split(\"/\")) > 1})\n",
    "lengthData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(lengthData.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lengthData['release_label']\n",
    "lengthData[(lengthData <= 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames['gender'] = {0: \"GenderID\", 1: \"GenderName\"} #, 3: \"NA3\", \"GenderDescr\"}\n",
    "\n",
    "ts = Timestat(\"Loading Gender Data\")\n",
    "files = [ifile for ifile in dumpDir.glob(\"gender*\")]\n",
    "genderData = getData(files, colnames)\n",
    "genderData = setIndex(genderData)\n",
    "ts.stop()\n",
    "\n",
    "io.save(idata=genderData['gender']['GenderName'], ifile=lookDir.join(\"Gender.p\"))\n",
    "del genderData\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"area_type\"] = {0: \"AreaTypeID\", 1: \"AreaTypeName\", 3: \"AlsoAreaTypeID\", 4: \"AreaTypeDescr\", 5: \"AreaTypeGID\"}\n",
    "colnames[\"area\"]      = {0: \"AreaID\", 1: \"AreaGID\", 2: \"AreaName\", 3: \"AreaTypeID\"}\n",
    "#colnames[\"area_gid_redirect\"] = {0: \"AreaGIDUUID\", 1: \"AreaGID\"}\n",
    "#colnames[\"area_alias_type\"] = {0: \"AreaAliasTypeID\", 1: \"AreaAliasTypeName\", 5: \"AreaAliasTypeUUID\"}\n",
    "#colnames[\"area_alias\"] = {0: \"AreaAliasID\", 1: \"NA1\", 2: \"AreaAlias\", 3: \"AreaLang\", 6: \"AliasTypeID\", 7: \"AreaSortName\"}\n",
    "\n",
    "ts = Timestat(\"Loading Area Data\")\n",
    "files = dumpDir.glob(\"area*\")\n",
    "areaData = getData(files, colnames)\n",
    "areaData = setIndex(areaData)\n",
    "ts.stop()\n",
    "\n",
    "io.save(idata=areaData['area']['AreaName'], ifile=lookDir.join(\"Area.p\"))\n",
    "del areaData\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames['isrc'] = {0: \"ISRCID\", 1: \"RecordingID\", 2: \"ISRC\"}\n",
    "colnames['iswc'] = {0: \"ISWCID\", 1: \"WorkID\", 2: \"ISWC\"}\n",
    "colnames['iso_3166_1'] = {0: \"ISO31661ID\", 1: \"ISO31661\"}\n",
    "colnames['iso_3166_2'] = {0: \"ISO31662ID\", 1: \"ISO31662\"}\n",
    "colnames['iso_3166_3'] = {0: \"ISO31663ID\", 1: \"ISO31663\"}\n",
    "\n",
    "ts = Timestat(\"Loading i* Code Data\")\n",
    "files = dumpDir.glob(\"is*\")\n",
    "icodeData = getData(files, colnames)\n",
    "icodeData = setIndex(icodeData)\n",
    "ts.stop()\n",
    "\n",
    "iSWCData = icodeData['iswc'][\"ISWC\"].copy(deep=True)\n",
    "iSWCData.index = icodeData['iswc']['WorkID']\n",
    "iSWCData = iSWCData.drop_duplicates()\n",
    "\n",
    "io.save(idata=iSWCData, ifile=lookDir.join(\"iSWC.p\"))\n",
    "del iSWCData\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"language\"] = {0: \"LanguageID\", 1: \"LanguageShort1\", 2: \"LanguageShort2\", 3: \"LanguageShort3\", 4: \"LanguageName\", 5: \"NA5\", 6: \"LanguageShort\"}\n",
    "\n",
    "ts = Timestat(\"Loading URL Data\")\n",
    "files = dumpDir.glob(\"language*\")\n",
    "languageData = getData(files, colnames)\n",
    "languageData = setIndex(languageData)\n",
    "ts.stop()\n",
    "\n",
    "io.save(idata=languageData['language']['LanguageName'], ifile=lookDir.join(\"Language.p\"))\n",
    "del languageData\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"script\"] = {0: \"ScriptID\", 1: \"ScriptName\", 2: \"NA2\", 3: \"ScriptDescr\", 4: \"NA4\"}\n",
    "\n",
    "ts = Timestat(\"Loading URL Data\")\n",
    "files = dumpDir.glob(\"script\")\n",
    "scriptData = getData(files, colnames)\n",
    "scriptData = setIndex(scriptData)\n",
    "ts.stop()\n",
    "\n",
    "io.save(idata=scriptData['script']['ScriptName'], ifile=lookDir.join(\"Script.p\"))\n",
    "del scriptData\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"label_alias\"] = {0: \"LabelAliasID\", 1: \"LabelID\", 2: \"LabelAliasName\", 7: \"LabelAliasName2\"}\n",
    "colnames[\"label_alias_type\"] = {0: \"LabelAliasTypeID\", 1: \"LabelAliasTypeName\", 5: \"LabelAliasGID\"}\n",
    "colnames[\"label_ipi\"] = {0: \"LabelIPIID\", 1: \"LabelIPI\"}\n",
    "colnames[\"label_isni\"] = {0: \"LabelISNIID\", 1: \"LabelISNI\"}\n",
    "colnames[\"label_type\"] = {0: \"LabelTypeID\", 1: \"LabelTypeName\", 5: \"LabelTypeGID\"}\n",
    "colnames[\"label\"] = {0: \"LabelID\", 1: \"LabelGID\", 2: \"LabelName\"}\n",
    "\n",
    "ts = Timestat(\"Loading Label Data\")\n",
    "files = dumpDir.glob(\"label*\")\n",
    "labelData = getData(files, colnames)\n",
    "labelData = setIndex(labelData)\n",
    "ts.stop()\n",
    "\n",
    "io.save(idata=labelData['label']['LabelName'], ifile=lookDir.join(\"Label.p\"))\n",
    "del labelData\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames['gender'] = {0: \"GenderID\", 1: \"GenderName\"} #, 3: \"NA3\", \"GenderDescr\"}\n",
    "\n",
    "ts = Timestat(\"Loading Gender Data\")\n",
    "files = dumpDir.glob(\"gender*\")\n",
    "genderData = getData(files, colnames)\n",
    "genderData = setIndex(genderData)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"GenderData.p\")\n",
    "io.save(idata=genderData, ifile=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"l_label_release\"] = {0: \"Index\", 1: \"NA1\", 2: \"NA2\", 3: \"ReleaseID\"}\n",
    "\n",
    "ts = Timestat(\"Loading Area Data\")\n",
    "files = glob(\"mbdump/l_label_release\")\n",
    "lookupData = {FileInfo(ifile).basename: loadData(ifile) for ifile in files}\n",
    "lookupData = {key: val[list(colnames[key].keys())].rename(columns=colnames[key]) for key,val in lookupData.items()} if colnames is not None else lookupData\n",
    "print(\"Keys: {0}\".format(lookupData.keys()))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData['l_label_release'][lookupData['l_label_release']['ReleaseID'].isin(releaseIDs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData['l_label_release'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"area_type\"] = {0: \"AreaTypeID\", 1: \"AreaTypeName\", 3: \"AlsoAreaTypeID\", 4: \"AreaTypeDescr\", 5: \"AreaTypeGID\"}\n",
    "colnames[\"area\"]      = {0: \"AreaID\", 1: \"AreaGID\", 2: \"AreaName\", 3: \"AreaTypeID\"}\n",
    "#colnames[\"area_gid_redirect\"] = {0: \"AreaGIDUUID\", 1: \"AreaGID\"}\n",
    "#colnames[\"area_alias_type\"] = {0: \"AreaAliasTypeID\", 1: \"AreaAliasTypeName\", 5: \"AreaAliasTypeUUID\"}\n",
    "#colnames[\"area_alias\"] = {0: \"AreaAliasID\", 1: \"NA1\", 2: \"AreaAlias\", 3: \"AreaLang\", 6: \"AliasTypeID\", 7: \"AreaSortName\"}\n",
    "\n",
    "ts = Timestat(\"Loading Area Data\")\n",
    "files = dumpDir.glob(\"area*\")\n",
    "areaData = getData(files, colnames)\n",
    "areaData = setIndex(areaData)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"AreaData.p\")\n",
    "io.save(idata=areaData, ifile=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"event_type\"] = {0: \"EventTypeID\", 1: \"EventTypeName\", 4: \"EventTypeDescr\"}\n",
    "colnames[\"event_alias_type\"] = {0: \"EventAliasTypeID\", 1: \"EventAliasTypeName\", 5: \"EventAliasTypeGID\"}\n",
    "colnames[\"event_alias\"] = {0: \"EventAliasID\", 1: \"EventID\", 2: \"EventAliasName\", 3: \"EventAliasLang\", 7: \"EventAliasName2\"}\n",
    "colnames[\"event\"] = {0: \"EventID\", 1: \"EventGID\", 2: \"EventName\", \n",
    "                     3: \"EventStartYear\", 4: \"EventStartMonth\", 5: \"EventStartDay\", 6: \"EventEndYear\", 7: \"EventEndMonth\", 8: \"EventEndDay\"}\n",
    "\n",
    "ts = Timestat(\"Loading Event Data\")\n",
    "files = glob(\"mbdump/event*\")\n",
    "eventData = {FileInfo(ifile).basename: loadData(ifile) for ifile in files}\n",
    "print(\"Keys: {0}\".format(eventData.keys()))\n",
    "eventData = {key: val[list(colnames[key].keys())].rename(columns=colnames[key]) for key,val in eventData.items() if key in colnames} if colnames is not None else eventData\n",
    "print(\"Keys: {0}\".format(eventData.keys()))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eventData['event']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ICode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames['isrc'] = {0: \"ISRCID\", 1: \"RecordingID\", 2: \"ISRC\"}\n",
    "colnames['iswc'] = {0: \"ISWCID\", 1: \"WorkID\", 2: \"ISWC\"}\n",
    "colnames['iso_3166_1'] = {0: \"ISO31661ID\", 1: \"ISO31661\"}\n",
    "colnames['iso_3166_2'] = {0: \"ISO31662ID\", 1: \"ISO31662\"}\n",
    "colnames['iso_3166_3'] = {0: \"ISO31663ID\", 1: \"ISO31663\"}\n",
    "\n",
    "ts = Timestat(\"Loading i* Code Data\")\n",
    "files = glob(\"mbdump/is*\")\n",
    "icodeData = getData(files, colnames)\n",
    "icodeData = setIndex(icodeData)\n",
    "ts.stop()\n",
    "\n",
    "iSWCData = icodeData['iswc'][\"ISWC\"].copy(deep=True)\n",
    "iSWCData.index = icodeData['iswc']['WorkID']\n",
    "iSWCData = iSWCData.drop_duplicates()\n",
    "del icodeData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"medium_format\"] = {0: \"MediumFormatID\", 1: \"MediumName\", 2: \"MediumGroupID\", 3: \"NA3\", 4: \"MediumIntroYear\", 5: \"MediumDescr\", 6: \"MediumGID\"}\n",
    "#colnames[\"medium_cdtoc\"]  = {0: \"NA0\", 1: \"NA1\", 2: \"NA2\", 3: \"NA3\"}\n",
    "colnames[\"medium\"] = {0: \"ReleaseID_1\", 1: \"ReleaseID\", 2: \"SideNum\", 3: \"MediumFormatID\", 4: \"NA4\", 5: \"NA5\", 7: \"NumTracks\"}\n",
    "\n",
    "ts = Timestat(\"Loading Medium Data\")\n",
    "files = glob(\"mbdump/medium*\")\n",
    "mediumData = {FileInfo(ifile).basename: loadData(ifile) for ifile in files}\n",
    "print(\"Keys: {0}\".format(mediumData.keys()))\n",
    "mediumData = {key: val[list(colnames[key].keys())].rename(columns=colnames[key]) for key,val in mediumData.items() if key in colnames} if colnames is not None else mediumData\n",
    "print(\"Keys: {0}\".format(mediumData.keys()))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium_format'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 12\" Vinyl ; ReleaseID=1310220\n",
    "#mediumData['medium'][mediumData['medium'].eq(1310220).any(1)]\n",
    "# MediumID  ReleaseID  Sides?  Format?   ?\n",
    "# 1310220   1274390    1       33        4\n",
    "# 1351220   1310220    1       31        11      <- Matches https://musicbrainz.org/release/6b5f33a8-fc5e-4c1e-b379-c659ce20a1c8\n",
    "\n",
    "\n",
    "## Digital Media : ReleaseID=1792210\n",
    "#mediumData['medium'][mediumData['medium'].eq(1792210).any(1)]\n",
    "# MediumID  ReleaseID  Sides?  Format?   ?\n",
    "# 1792210   1694923    1      12\tNaN\t0\t2015-11-30 00:32:22.335038+00\t13\n",
    "# 1904010   1792210    1      12\tNaN\t0\t2016-06-20 18:41:01.106192+00\t11   Both Match\n",
    "\n",
    "\n",
    "# 2x12\" Vinyl ; ReleaseID=1680415\n",
    "\n",
    "#mediumData['medium'][mediumData['medium'].eq(1680415).any(1)]\n",
    "# MediumID  ReleaseID  Sides?  Format?   ?\n",
    "# 1680415\t1598741\t1\t1\tNaN\t0\t2015-04-27 04:37:49.277705+00\t11\n",
    "# 1775088\t1680415\t1\t31\tNaN\t0\t2015-10-31 12:02:35.843886+00\t5\n",
    "# 1775089\t1680415\t2\t31\tNaN\t0\t2015-10-31 12:02:35.843886+00\t6\n",
    "\n",
    "# 1792210   1694923    1      12\tNaN\t0\t2015-11-30 00:32:22.335038+00\t13\n",
    "# 1904010   1792210    1      12\tNaN\t0\t2016-06-20 18:41:01.106192+00\t11   Both Match\n",
    "\n",
    "# Pixies Velouria CD w/ 4 Tracks\n",
    "# 3099, 1162482, 3097, 2259927\n",
    "\n",
    "## CD\n",
    "# mediumData['medium'][mediumData['medium'].eq(3099).any(1)]\n",
    "# 3099\t3099\t1\t1\tNaN\t0\t2011-05-16 14:57:06.530063+00\t4\n",
    "\n",
    "## CD (Status=Promotional)\n",
    "# mediumData['medium'][mediumData['medium'].eq(1162482).any(1)]\n",
    "# 1162482\t1146184\t1\t12\tNaN\t0\t2012-04-14 05:35:56.931961+00\t1\n",
    "# 1181517\t1162482\t1\t1\tNaN\t0\t2012-05-30 00:53:24.512335+00\t4\n",
    "\n",
    "## CD\n",
    "# mediumData['medium'][mediumData['medium'].eq(3097).any(1)]\n",
    "# 3097\t3097\t1\t1\tNaN\t0\t2012-10-18 19:49:17.567219+00\t4\n",
    "\n",
    "## 12\" Vinyl\n",
    "# mediumData['medium'][mediumData['medium'].eq(2259927).any(1)]\n",
    "# 2259927\t2099781\t1\t12\tNaN\t0\t2018-01-11 08:03:13.107915+00\t5\n",
    "# 2441117\t2259927\t1\t31\tNaN\t0\t2018-09-28 23:20:29.279923+00\t4  <-- This matches Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium_cdtoc'][mediumData['medium_cdtoc'].eq(1598741).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium_format'][mediumData['medium_format'].eq(38).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium_format'][mediumData['medium_format'].eq('38').any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium_format'][mediumData['medium_format'].eq(63).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mediumData['medium_format'][mediumData['medium_format'].eq(64).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"language\"] = {0: \"LanguageID\", 1: \"LanguageShort1\", 2: \"LanguageShort2\", 3: \"LanguageShort3\", 4: \"LanguageName\", 5: \"NA5\", 6: \"LanguageShort\"}\n",
    "\n",
    "ts = Timestat(\"Loading URL Data\")\n",
    "files = dumpDir.glob(\"language*\")\n",
    "languageData = getData(files, colnames)\n",
    "languageData = setIndex(languageData)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"LanguageData.p\")\n",
    "io.save(idata=languageData, ifile=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"script\"] = {0: \"ScriptID\", 1: \"ScriptName\", 2: \"NA2\", 3: \"ScriptDescr\", 4: \"NA4\"}\n",
    "\n",
    "ts = Timestat(\"Loading Script Data\")\n",
    "files = dumpDir.glob(\"script\")\n",
    "scriptData = getData(files, colnames)\n",
    "scriptData = setIndex(scriptData)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"ScriptData.p\")\n",
    "io.save(idata=scriptData, ifile=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"url\"] = {0: \"URLID\", 1: \"URLGID\", 2: \"URLName\"}\n",
    "#colnames[\"url_gid_redirect\"] = {0: \"URLGIDUUID\", 1: \"URLGIDID\"}\n",
    "\n",
    "ts = Timestat(\"Loading URL Data\")\n",
    "files = dumpDir.glob(\"url*\")\n",
    "urlData = getData(files, colnames)\n",
    "urlData = setIndex(urlData)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"URLData.p\")\n",
    "io.save(idata=urlData, ifile=savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"work_type\"] = {0: \"WorkTypeID\", 1: \"WorkTypeName\", 3: \"WorkTypeRanking\", 4: \"WorkTypeDescr\", 5: \"WorkTypeGID\"}\n",
    "#colnames[\"work_alias\"] = {0: \"WorkAliasID\", 1: \"WorkID\", 2: \"WorkName\", 3: \"WorkLang\", 7: \"WorkName2\"}\n",
    "#colnames[\"work_alias_type\"] = {0: \"WorkAliasTypeID\", 1: \"WorkAliasTypeName\", 5: \"WorkAliasTypeGID\"}\n",
    "colnames['work_attribute_type_allowed_value'] = {0: 'WorkAttributeTypeValueID', 1: \"WorkAttributeTypeID\", 2: \"WorkAttributeTypeValue\", 6: \"WorkAttributeTypeValueGID\"}\n",
    "colnames[\"work_attribute_type\"] = {0: \"WorkAttributeTypeID\", 1: \"WorkAttributeTypeName\", 6: \"WorkAttributeTypeDescr\"}\n",
    "colnames[\"work_attribute\"] = {0: \"WorkAttributeID\", 1: \"WorkID\", 2: \"WorkAttributeTypeID\", 3: \"WorkAttributeTypeValueID\", 4: \"WorkAttributeCode\"}\n",
    "colnames[\"work_language\"] = {0: \"WorkID\", 1: \"LanguageID\"}\n",
    "colnames[\"work\"] = {0: \"WorkID\", 1: \"WorkGID\", 2: \"WorkName\", 3: \"WorkTypeID\"} #, 4: \"WorkDescr\"}\n",
    "\n",
    "ts = Timestat(\"Loading Work Data\")\n",
    "files = dumpDir.glob(\"work*\")\n",
    "workData = getData(files, colnames)\n",
    "workData = setIndex(workData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Data And Create Master Work DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Joining Release Language Name\")\n",
    "try:\n",
    "    languageData  = io.get(saveDir.join(\"LanguageData.p\"))\n",
    "    dLanguageName = languageData['language'][\"LanguageName\"]\n",
    "except:\n",
    "    raise ValueError(\"Error loading language data\")\n",
    "workData['work_language'][\"Language\"] = workData['work_language']['LanguageID'].apply(lambda x: dLanguageName.get(x) if not isna(x) else None)\n",
    "workData['work_language'].drop([\"LanguageID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Work Attribute Type\")\n",
    "dWorkAttributeTypeName = workData['work_attribute_type'][\"WorkAttributeTypeName\"].to_dict()\n",
    "workData['work_attribute_type_allowed_value'][\"WorkAttributeType\"] = workData['work_attribute_type_allowed_value']['WorkAttributeTypeID'].apply(lambda x: dWorkAttributeTypeName.get(x) if not isna(x) else None)\n",
    "workData['work_attribute_type_allowed_value'].drop([\"WorkAttributeTypeID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Work Attribute Type\")\n",
    "dWorkAttributeTypeName = workData['work_attribute_type'][\"WorkAttributeTypeName\"].to_dict()\n",
    "workData['work_attribute'][\"WorkAttributeType\"] = workData['work_attribute']['WorkAttributeTypeID'].apply(lambda x: dWorkAttributeTypeName.get(x) if not isna(x) else None)\n",
    "workData['work_attribute'].drop([\"WorkAttributeTypeID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Work Type\")\n",
    "dWorkTypeName = workData['work_type'][\"WorkTypeName\"].to_dict()\n",
    "workData['work'][\"WorkTypeName\"] = workData['work']['WorkTypeID'].apply(lambda x: dWorkTypeName.get(int(x)) if not isna(x) else None)\n",
    "workData['work'].drop([\"WorkTypeID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "###\n",
    "# Ignore Work Attributes\n",
    "###\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "workData['work'].drop([\"WorkGID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"WorkDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master Release DataFrame To {0}\".format(savename.str))\n",
    "io.save(idata=workData, ifile=savename)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"label_alias\"] = {0: \"LabelAliasID\", 1: \"LabelID\", 2: \"LabelAliasName\", 7: \"LabelAliasName2\"}\n",
    "colnames[\"label_alias_type\"] = {0: \"LabelAliasTypeID\", 1: \"LabelAliasTypeName\", 5: \"LabelAliasGID\"}\n",
    "colnames[\"label_ipi\"] = {0: \"LabelIPIID\", 1: \"LabelIPI\"}\n",
    "colnames[\"label_isni\"] = {0: \"LabelISNIID\", 1: \"LabelISNI\"}\n",
    "colnames[\"label_type\"] = {0: \"LabelTypeID\", 1: \"LabelTypeName\", 5: \"LabelTypeGID\"}\n",
    "colnames[\"label\"] = {0: \"LabelID\", 1: \"LabelGID\", 2: \"LabelName\"}\n",
    "\n",
    "ts = Timestat(\"Loading Label Data\")\n",
    "files = dumpDir.glob(\"label*\")\n",
    "labelData = getData(files, colnames)\n",
    "labelData = setIndex(labelData)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"LabelData.p\")\n",
    "io.save(idata=labelData, ifile=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "#colnames[\"recording_alias_type\"] = {0: \"RecordingAliasTypeID\", 1: \"RecordingAliasTypeName\"}\n",
    "#colnames[\"recording_alias\"] = {0: \"RecordingAliasID\", 1: \"RecordingID\", 2: \"RecordingAliasName\", 3: \"RecordingAliasLang\", 7: \"recordingAliasName2\"}\n",
    "colnames[\"recording\"] = {0: \"RecordingID\", 1: \"RecordingGID\", 2: \"RecordingName\", 3: \"ArtistID\", 4: \"TimeLength\"} #, 5: \"RecordingDescr\"}\n",
    "\n",
    "ts = Timestat(\"Loading Recording Data\")\n",
    "files = dumpDir.glob(\"recording*\")\n",
    "recordingData = getData(files, colnames)\n",
    "recordingData = setIndex(recordingData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Data And Create Master Recording DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "recordingData['recording'].drop([\"RecordingGID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"RecordingDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master Recording DataFrame To {0} (~1.1 min)\".format(savename.str))\n",
    "io.save(idata=recordingData, ifile=savename)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"track\"] = {0: \"TrackID\", 1: \"TrackGID\", 2: \"RecordingID\", 3: \"NA3\", 4: \"TrackNum\", 5: \"TrackNumName\", 6: \"TrackName\", 7: \"ArtistID\", 8: \"TimeLength\"}\n",
    "\n",
    "# Release\n",
    "# 2373946\t7c5d14b4-cf40-4eb1-89e6-d448125d94f3\t1987-12-12: Hampton Coliseum, Hampton, VA, USA\t197\t2128729\t3\t\\N\t120\t28\t\\N\t\t0\t-1\t2019-03-15 09:46:50.446876+00\n",
    "            \n",
    "# Release Group\n",
    "# 2128729\tf979a1c6-b6c2-4aad-b5b6-709c6c216752\t1987-12-12: Hampton Coliseum, Hampton, VA, USA\t197\t1\t\t0\t2019-03-15 09:46:45.458509+00\n",
    "\n",
    "# Recording\n",
    "# 24365864\t6a355a78-06c0-4e06-a15e-05d6e533255e\tSunday Bloody Sunday\t197\t366000\t\t0\t2019-03-15 12:29:22.049215+00\tf\n",
    "\n",
    "# Track\n",
    "# 27710495\tfc969b10-fdba-4b0c-82d9-aa6a7179e41f\t24365864\t2571008\t7\t7\tSunday Bloody Sunday\t197\t366000\t0\t2019-03-15 12:29:22.049215+00\tf\n",
    "ts = timestat(\"Loading Recording Data\")\n",
    "files = glob(\"mbdump/track\")\n",
    "trackData = {fileInfo(ifile).basename: loadData(ifile) for ifile in files}\n",
    "print(\"Keys: {0}\".format(trackData.keys()))\n",
    "trackData = {key: val[list(colnames[key].keys())].rename(columns=colnames[key]) for key,val in trackData.items() if key in colnames} if colnames is not None else trackData\n",
    "print(\"Keys: {0}\".format(trackData.keys()))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "#colnames[\"release_alias_type\"] = {0: \"ReleaseAliasTypeID\", 1: \"ReleaseAliasTypeName\"}\n",
    "#colnames[\"release_alias\"] = {0: \"ReleaseAliasID\", 1: \"ReleaseID\", 2: \"ReleaseAliasName\", 3: \"ReleaseAliasLang\", 7: \"ReleaseAliasName2\"}\n",
    "colnames[\"release_status\"] = {0: \"ReleaseStatusID\", 1: \"ReleaseStatusName\", 3: \"NA3\", 3: \"ReleaseStatusDescr\", 4: \"ReleaseStatusGID\"}\n",
    "colnames[\"release_packaging\"] = {0: \"ReleasePackagingID\", 1: \"ReleasePackagingName\", 3: \"NA3\", 4: \"ReleasePackagingDescr\", 5: \"ReleaseStatusGID\"}\n",
    "colnames[\"release_label\"] = {0: \"Index\", 1: \"ReleaseID\", 2: \"LabelID\", 3: \"CatalogNumber\"}\n",
    "colnames[\"release_country\"] = {0: \"ReleaseID\", 1: \"ReleaseCountryID\", 2: \"ReleaseCountryYear\", 3: \"ReleaseCountryMonth\", 4: \"ReleaseCountryDay\"}\n",
    "colnames[\"release_unknown_country\"] = {0: \"ReleaseID\", 1: \"ReleaseCountryYear\", 2: \"ReleaseCountryMonth\", 3: \"ReleaseCountryDay\"}\n",
    "colnames[\"release\"] = {0: \"ReleaseID\", 1: \"ReleaseGID\", 2: \"ReleaseName\", 3: \"ArtistID\", 4: \"ReleaseGroupID\", 5: \"ReleaseStatusID\", \n",
    "                       6: \"ReleasePackagingID\", 7: \"LanguageID\", 8: \"ScriptID\", 9: \"ReleaseBarcode\", 10: \"ReleaseComment\", 11: \"NA11\", 12: \"NA12\"}\n",
    "\n",
    "ts = Timestat(\"Loading Release Data\")\n",
    "files = [ifile for ifile in dumpDir.glob(\"release*\") if \"group\" not in str(ifile)]\n",
    "releaseData = getData(files, colnames)\n",
    "releaseData = setIndex(releaseData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Data And Create Master Release DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsRelease = Timestat(\"Appending Release Data\")\n",
    "\n",
    "ts = Timestat(\"Creating Release Country DateTime For {0} Releases\".format(releaseData['release_country'].shape[0]))\n",
    "tmp = releaseData['release_country'][[\"ReleaseCountryYear\", \"ReleaseCountryMonth\", \"ReleaseCountryDay\"]]\n",
    "tmp.columns = [\"year\", \"month\", \"day\"]\n",
    "releaseData['release_country']['ReleaseDate'] = to_datetime(tmp, errors='ignore')\n",
    "releaseData['release_country'].drop([\"ReleaseCountryYear\", \"ReleaseCountryMonth\", \"ReleaseCountryDay\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Creating Release Unknown Country DateTime For {0} Releases\".format(releaseData['release_unknown_country'].shape[0]))\n",
    "tmp = releaseData['release_unknown_country'][[\"ReleaseCountryYear\", \"ReleaseCountryMonth\", \"ReleaseCountryDay\"]]\n",
    "tmp.columns = [\"year\", \"month\", \"day\"]\n",
    "releaseData['release_unknown_country']['ReleaseDate'] = to_datetime(tmp, errors='ignore')\n",
    "releaseData['release_unknown_country'].drop([\"ReleaseCountryYear\", \"ReleaseCountryMonth\", \"ReleaseCountryDay\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Country Area\")\n",
    "try:                         \n",
    "    areaData  = io.get(saveDir.join(\"AreaData.p\"))\n",
    "    dAreaName = areaData['area']['AreaName']\n",
    "except:\n",
    "    raise ValueError(\"Error loading area data\")    \n",
    "releaseData['release_country'][\"Country\"] = releaseData['release_country']['ReleaseCountryID'].apply(lambda x: dAreaName.get(x) if not isna(x) else None)\n",
    "releaseData['release_country'].drop([\"ReleaseCountryID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Release Packaging Name\")\n",
    "dReleasePackagingName = releaseData['release_packaging']['ReleasePackagingName'].to_dict()\n",
    "releaseData['release'][\"Packaging\"] = releaseData['release']['ReleasePackagingID'].apply(lambda x: dReleasePackagingName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "releaseData['release'].drop([\"ReleasePackagingID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Release Status Name\")\n",
    "dReleaseStatusName = releaseData['release_status']['ReleaseStatusName'].to_dict()\n",
    "releaseData['release'][\"Status\"] = releaseData['release']['ReleaseStatusID'].apply(lambda x: dReleaseStatusName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "releaseData['release'].drop([\"ReleaseStatusID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Release Language Name\")\n",
    "try:                         \n",
    "    areaData  = io.get(saveDir.join(\"LanguageData.p\"))\n",
    "    dLanguageName = languageData['language']['LanguageName']\n",
    "except:\n",
    "    raise ValueError(\"Error loading language data\")\n",
    "releaseData['release'][\"Language\"] = releaseData['release']['LanguageID'].apply(lambda x: dLanguageName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "releaseData['release'].drop([\"LanguageID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Release Script Name\")\n",
    "try:                         \n",
    "    areaData  = io.get(saveDir.join(\"ScriptData.p\"))\n",
    "    dScriptName = scriptData['script']['ScriptName']\n",
    "except:\n",
    "    raise ValueError(\"Error loading script data\")\n",
    "releaseData['release'][\"Script\"] = releaseData['release']['ScriptID'].apply(lambda x: dScriptName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "releaseData['release'].drop([\"ScriptID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Country/Release Date\")\n",
    "tmp = concat([releaseData['release_country'], releaseData['release_unknown_country']]).reset_index()\n",
    "releaseIDDate = tmp.sort_values(by=\"ReleaseDate\").drop_duplicates(subset=\"ReleaseID\")\n",
    "releaseIDDate.index = releaseIDDate['ReleaseID']\n",
    "releaseIDDate.drop([\"ReleaseID\"], axis=1, inplace=True)\n",
    "releaseData['release'] = releaseData['release'].join(releaseIDDate)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Label Data\")\n",
    "try:                         \n",
    "    areaData  = io.get(saveDir.join(\"LabelData.p\"))\n",
    "    dLabelName = labelData['label']['LabelName']\n",
    "except:\n",
    "    raise ValueError(\"Error loading label data\")\n",
    "releaseData['release_label'][\"Label\"] = releaseData['release_label']['LabelID'].apply(lambda x: dLabelName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "releaseLabel = releaseData['release_label'].drop_duplicates(subset=\"ReleaseID\")[[\"ReleaseID\", \"Label\"]].copy(deep=True)\n",
    "releaseLabel[\"Label\"].index = releaseLabel[\"ReleaseID\"]\n",
    "releaseData['release'].join(releaseLabel)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "releaseData['release'].drop([\"ReleaseComment\", \"ReleaseBarcode\", \"NA11\", \"NA12\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "savename = saveDir.join(\"ReleaseDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master Release DataFrame To {0}\".format(savename.str))\n",
    "io.save(idata=releaseData['release'], ifile=savename)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "tsRelease.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release-Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "#colnames[\"release_group_alias_type\"] = {0: \"ReleaseGroupAliasTypeID\", 1: \"ReleaseGroupAliasTypeName\"}\n",
    "#colnames[\"release_group_alias\"] = {0: \"ReleaseGroupAliasID\", 1: \"NA1\", 2: \"ReleaseGroupAliasName\", 3: \"ReleaseGroupAliasLang\", 7: \"ReleaseGroupAliasName2\"}\n",
    "colnames[\"release_group_primary_type\"] = {0: \"ReleaseGroupPrimaryTypeID\", 1: \"ReleaseGroupPrimaryTypeName\", 3: \"NA3\"}\n",
    "colnames[\"release_group_secondary_type\"] = {0: \"ReleaseGroupSecondaryTypeID\", 1: \"ReleaseGroupSecondaryTypeName\"}\n",
    "colnames[\"release_group\"] = {0: \"ReleaseGroupID\", 1: \"ReleaseGroupGID\", 2: \"ReleaseGroupName\", 3: \"ArtistID\", 4: \"ReleaseGroupPrimaryTypeID\", 5: \"ReleaseGroupComment\", 6: \"NA6\"}\n",
    "colnames[\"release_group_secondary_type_join\"] = {0: \"ReleaseGroupID\", 1: \"ReleaseGroupSecondaryTypeID\"}\n",
    "\n",
    "ts = Timestat(\"Loading Release Data\")\n",
    "files = [ifile for ifile in dumpDir.glob(\"release*\") if \"group\" in str(ifile)]\n",
    "releaseGroupData = getData(files, colnames)\n",
    "releaseGroupData = setIndex(releaseGroupData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Data And Create Master ReleaseGroup DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsReleaseGroup = Timestat(\"Appending ReleaseGroup Data\")\n",
    "\n",
    "ts = Timestat(\"Joining Secondary Type Names\")\n",
    "dReleaseGroupSecondaryTypeName = releaseGroupData['release_group_secondary_type']['ReleaseGroupSecondaryTypeName'].to_dict()\n",
    "releaseGroupData['release_group_secondary_type_join']['ReleaseGroupSecondaryType'] = releaseGroupData['release_group_secondary_type_join']['ReleaseGroupSecondaryTypeID'].apply(lambda x: dReleaseGroupSecondaryTypeName.get(x) if not isna(x) else None)\n",
    "releaseGroupData['release_group_secondary_type_join'].drop([\"ReleaseGroupSecondaryTypeID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Primary Type Names\")\n",
    "dReleaseGroupPrimaryTypeName = releaseGroupData['release_group_primary_type']['ReleaseGroupPrimaryTypeName'].to_dict()\n",
    "releaseGroupData['release_group']['ReleaseGroupPrimaryType'] = releaseGroupData['release_group']['ReleaseGroupPrimaryTypeID'].apply(lambda x: dReleaseGroupPrimaryTypeName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "releaseGroupData['release_group'].drop([\"ReleaseGroupPrimaryTypeID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Joining Release Group And Secondary Type Join Data\")\n",
    "releaseGroupData['release_group'] = releaseGroupData['release_group'].join(releaseGroupData['release_group_secondary_type_join'])\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "releaseGroupData['release_group'].drop([\"NA6\", \"ReleaseGroupComment\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "savename = saveDir.join(\"ReleaseGroupDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master ReleaseGroup DataFrame To {0} (~20 sec)\".format(savename.str))\n",
    "io.save(idata=releaseGroupData['release_group'], ifile=savename)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "tsReleaseGroup.stop()\n",
    "\n",
    "del releaseGroupData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"artist_credit\"] = {0: \"ArtistCreditID\", 1: \"ArtistCreditName\", 2: \"ArtistCreditNum\", 3: \"NA3\"}\n",
    "colnames[\"artist_type\"] = {0: \"ArtistTypeID\", 1: \"ArtistTypeName\", 2: \"NA2\", 3: \"NA3\", 4: \"ArtistTypeDescr\", 5: \"ArtistTypeGID\"}\n",
    "colnames[\"artist_isni\"] = {0: \"ArtistID\", 1: \"ISNICode\"}\n",
    "colnames[\"artist_alias_type\"] = {0: \"ArtistAliasTypeID\", 1: \"ArtistAliasTypeName\", 5: \"ArtistAliasTypeGID\"}\n",
    "colnames[\"artist_alias\"] = {0: \"ArtistAliasID\", 1: \"ArtistID\", 2: \"ArtistAliasName\", 3: \"ArtistAliasLang\", 7: \"ArtistAliasSortName\"}\n",
    "colnames[\"artist\"] = {0: \"ArtistID\", 1: \"ArtistGID\", 2: \"ArtistName\", 3: \"ArtistSortName\",\n",
    "                      4: \"FormedYear\", 5: \"FormedMonth\", 6: \"FormedDay\", \n",
    "                      7: \"DisbandedYear\", 8: \"DisbandedMonth\", 9: \"DisbandedDay\", \n",
    "                      10: \"ArtistTypeID\", 11: \"CountryAreaID\", 12: \"GenderID\", 13: \"ArtistDescr\", 14: \"NA14\", 17: \"FoundedInAreaID\", 18: \"DisbandedInAreaID\"}\n",
    "\n",
    "ts = Timestat(\"Loading Artist Data (~20 sec)\")\n",
    "files = [ifile for ifile in dumpDir.glob(\"artist*\") if str(ifile) not in [\"mbdump/artist_credit_name\"]]\n",
    "artistData = getData(files, colnames)\n",
    "artistData = setIndex(artistData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Data And Create Master Artist DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsArtist = Timestat(\"Appending Artist Data\")\n",
    "\n",
    "ts = Timestat(\"Creating Formed/Disbanded DateTime For {0} Artists (~7 sec)\".format(artistData['artist'].shape[0]))\n",
    "artistData['artist']['Formed']    = convertToDatetime(artistData['artist'][\"FormedYear\"], artistData['artist'][\"FormedMonth\"], artistData['artist'][\"FormedDay\"])\n",
    "artistData['artist']['Disbanded'] = convertToDatetime(artistData['artist'][\"DisbandedYear\"], artistData['artist'][\"DisbandedMonth\"], artistData['artist'][\"DisbandedDay\"])\n",
    "artistData['artist'].drop([\"FormedYear\", \"FormedMonth\", \"FormedDay\", \"DisbandedYear\", \"DisbandedMonth\", \"DisbandedDay\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "ts = Timestat(\"Joining Artist Type\")\n",
    "dArtistTypeName = artistData['artist_type'][\"ArtistTypeName\"]\n",
    "artistData['artist'][\"ArtistType\"] = artistData['artist']['ArtistTypeID'].apply(lambda x: dArtistTypeName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "artistData['artist'].drop([\"ArtistTypeID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "ts = Timestat(\"Joining Gender Type\")\n",
    "try:\n",
    "    genderData  = io.get(saveDir.join(\"GenderData.p\"))\n",
    "    dGenderName = genderData['gender']['GenderName']\n",
    "except:\n",
    "    raise ValueError(\"Error loading gender data\")\n",
    "artistData['artist']['Gender'] = artistData['artist']['GenderID'].apply(lambda x: dGenderName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "artistData['artist'].drop([\"GenderID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "                         \n",
    "ts = Timestat(\"Joining Area Type\")\n",
    "try:                         \n",
    "    areaData  = io.get(saveDir.join(\"AreaData.p\"))\n",
    "    dAreaName = areaData['area']['AreaName']\n",
    "except:\n",
    "    raise ValueError(\"Error loading area data\")\n",
    "\n",
    "                       \n",
    "artistData['artist'][\"Country\"]     = artistData['artist']['CountryAreaID'].apply(lambda x: dAreaName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "artistData['artist'][\"FormedIn\"]    = artistData['artist']['FoundedInAreaID'].apply(lambda x: dAreaName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "artistData['artist'][\"DisbandedIn\"] = artistData['artist']['DisbandedInAreaID'].apply(lambda x: dAreaName.get(int(x)) if (not isna(x) and x.isdigit()) else None)\n",
    "artistData['artist'].drop([\"CountryAreaID\", \"FoundedInAreaID\", \"DisbandedInAreaID\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "                       \n",
    "ts = Timestat(\"Joining ISNI\")\n",
    "artistData['artist'] = artistData['artist'].join(artistData['artist_isni'])\n",
    "ts.stop()\n",
    "                       \n",
    "\n",
    "ts = Timestat(\"Collecting and Joining Artist Aliases (~40 sec)\")\n",
    "artistAliases = DataFrame(Series({artistID: df[\"ArtistAliasName\"].to_list() for artistID,df in artistData['artist_alias'].groupby(\"ArtistID\")}))\n",
    "artistAliases.columns = [\"Aliases\"]\n",
    "artistData['artist'] = artistData['artist'].join(artistAliases)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "artistData['artist'].drop([\"ArtistDescr\", \"NA14\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "\n",
    "savename = saveDir.join(\"ArtistDataFrame.p\")\n",
    "ts = Timestat(f\"Saving Master Artist DataFrame To {savename.str} (~20 sec)\")\n",
    "io.save(idata=artistData['artist'], ifile=savename)\n",
    "ts.stop()\n",
    "\n",
    "tsArtist.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist <=> Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"l_artist_work\"] = {0: \"LookupID\", 1: \"WorkGroupID\", 2: \"ArtistID\", 3: \"WorkID\", 6: \"NA6\", 7: \"NA7\"}\n",
    "\n",
    "ts = Timestat(\"Loading Artist <=> Work Data\")\n",
    "files = dumpDir.glob(\"l_artist_work\")\n",
    "lookupData = getData(files, colnames)\n",
    "lookupData = setIndex(lookupData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Merging Artist <=> Work Lookup\")\n",
    "\n",
    "try:\n",
    "    workData = io.get(saveDir.join(\"WorkDataFrame.p\"))\n",
    "    wData = workData['work'].reset_index()\n",
    "except:\n",
    "    raise ValueError(\"Error loading work data\")\n",
    "    \n",
    "try:\n",
    "    lData = lookupData['l_artist_work'].reset_index()\n",
    "except:\n",
    "    raise ValueError(\"Error loading work data\")\n",
    "    \n",
    "mergedWorkData = merge(wData,lData,on='WorkID')\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "mergedWorkData.drop([\"WorkID\", \"LookupID\", \"NA6\", \"NA7\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Grouping By ArtistID (~31 sec)\")\n",
    "artistWorks = Series({artistID: list(zip(artistIDWorks[\"WorkGroupID\"], artistIDWorks[\"WorkTypeName\"], artistIDWorks[\"WorkName\"])) for artistID,artistIDWorks in mergedWorkData.groupby(\"ArtistID\")})\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"ArtistWorkDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master Artist Work DataFrame To {0} (~6 sec)\".format(savename.str))\n",
    "io.save(idata=artistWorks, ifile=savename)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist <=> Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"l_artist_recording\"] = {0: \"LookupID\", 1: \"RecordingGroupID\", 2: \"ArtistID\", 3: \"RecordingID\", 6: \"NA6\", 7: \"NA7\"}\n",
    "\n",
    "ts = Timestat(\"Loading Artist <=> Recording Data\")\n",
    "files = dumpDir.glob(\"l_artist_recording\")\n",
    "lookupData = getData(files, colnames)\n",
    "lookupData = setIndex(lookupData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordingData = io.get(saveDir.join(\"RecordingDataFrame.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Merging Artist <=> Recording Lookup (~16 sec)\")\n",
    "\n",
    "try:\n",
    "    recordingData = io.get(saveDir.join(\"RecordingDataFrame.p\"))\n",
    "    rData = recordingData['recording'].reset_index().drop([\"ArtistID\"], axis=1)\n",
    "except:\n",
    "    raise ValueError(\"Error loading recording data\")\n",
    "    \n",
    "lData = lookupData['l_artist_recording'].reset_index()\n",
    "mergedRecordingData = merge(rData,lData,on='RecordingID')\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "mergedRecordingData.drop([\"RecordingID\", \"RecordingGroupID\", \"LookupID\", \"NA6\", \"NA7\"], axis=1, inplace=True)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Grouping By ArtistID (~31 sec)\")\n",
    "artistRecordings = Series({artistID: list(zip(artistIDRecordings[\"RecordingName\"], artistIDRecordings[\"TimeLength\"])) for artistID,artistIDRecordings in mergedRecordingData.groupby(\"ArtistID\")})\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"ArtistRecordingDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master Artist Recording DataFrame To {0} (~54 sec)\".format(savename))\n",
    "io.save(idata=artistRecordings, ifile=savename)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Artist <=> Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#### Seems not to be used ####\n",
    "#### Seems not to be used ####\n",
    "#### Seems not to be used ####\n",
    "\n",
    "\n",
    "colnames = {}\n",
    "colnames[\"l_artist_release\"] = {0: \"LookupID\", 1: \"ReleaseGroupID\", 2: \"ArtistID\", 3: \"ReleaseID\", 6: \"NA6\", 7: \"NA7\"}\n",
    "\n",
    "ts = Timestat(\"Loading Artist <=> Release Data\")\n",
    "files = dumpDir.glob(\"l_artist_release\")\n",
    "lookupData = getData(files, colnames)\n",
    "lookupData = setIndex(lookupData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "savename = saveDir.join(\"ReleaseDataFrame.p\")\n",
    "releaseData = FileIO().get(savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist <=> URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = {}\n",
    "colnames[\"l_artist_url\"] = {0: \"LookupID\", 1: \"URLGroupID\", 2: \"ArtistID\", 3: \"URLID\", 6: \"NA6\", 7: \"NA7\"}\n",
    "\n",
    "ts = Timestat(\"Loading Artist <=> URL Data\")\n",
    "files = dumpDir.glob(\"l_artist_url\")\n",
    "lookupData = getData(files, colnames)\n",
    "lookupData = setIndex(lookupData)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Joining URLs\")\n",
    "\n",
    "try:\n",
    "    urlData = io.get(saveDir.join(\"URLData.p\"))\n",
    "except:\n",
    "    raise ValueError(\"Error loading URL data\")\n",
    "lookupData['l_artist_url'][\"URL\"] = lookupData['l_artist_url']['URLID'].apply(lambda x: urlData['url'][\"URLName\"].get(x))\n",
    "ts.stop()\n",
    "\n",
    "urlType={'26038': 'Discogs',\n",
    " '26039': 'Myspace',\n",
    " '26040': 'IMDB',\n",
    " '26041': 'Wikipedia',\n",
    " '26042': 'Artist',\n",
    " '26048': 'LastFMMisc',\n",
    " '26052': 'Apple',\n",
    " '26055': 'YouTube',\n",
    " '26056': 'Facebook',\n",
    " '26062': 'GeniusMisc',\n",
    " '26068': 'VGMDB',\n",
    " '26316': 'DeezerSpotify',\n",
    " '28613': 'AllMusic',\n",
    " '30134': 'Soundcloud',\n",
    " '41329': 'Video',\n",
    " '49052': 'RateYourMusicMisc',\n",
    " '94979': 'SecondhandSongs',\n",
    " '106477': 'VIAG',\n",
    " '117675': 'Wikidata',\n",
    " '139284': 'Bandcamp',\n",
    " '195003': 'IMSLP',\n",
    " '199852': 'Songkick',\n",
    " '204138': 'Setlist.fm',\n",
    " '215573': 'Last.fm',\n",
    " '240791': 'BandsInTown',\n",
    " '624633': 'AppleTidalNapster',\n",
    " '697028': 'PureVolume',\n",
    " '732275': 'CDBaby',\n",
    " '748510': 'GooglePlus',\n",
    " '753046': 'GooglePlay',\n",
    " '771457': 'BBC'}\n",
    "\n",
    "def getURLGroupName(url):\n",
    "    if \"discogs.\" in url:\n",
    "        return \"Discogs\"\n",
    "    elif \"myspace.\" in url:\n",
    "        return \"Myspace\"\n",
    "    elif \"imdb.\" in url:\n",
    "        return \"IMDB\"\n",
    "    elif \"youtube.\" in url:\n",
    "        return \"YouTube\"\n",
    "    elif \"allmusic.\" in url:\n",
    "        return \"AllMusic\"\n",
    "    elif \"last.fm\" in url:\n",
    "        return \"LastFM\"\n",
    "    elif \"soundcloud.\" in url:\n",
    "        return \"Soundcloud\"\n",
    "    elif \"directlyrics.\" in url:\n",
    "        return \"DirectLyrics\"\n",
    "    elif \"facebook.\" in url:\n",
    "        return \"Facebook\"\n",
    "    elif \"tumblr.\" in url:\n",
    "        return \"Tumblr\"\n",
    "    elif \"viaf.\" in url:\n",
    "        return \"VIAF\"\n",
    "    elif \"wikidata.\" in url:\n",
    "        return \"Wikidata\"\n",
    "    elif \"rateyourmusic.\" in url:\n",
    "        return \"RateYourMusic\"\n",
    "    elif \"muzikum.\" in url:\n",
    "        return \"Muzikum\"\n",
    "    elif \"spotify.\" in url:\n",
    "        return \"Spotify\"\n",
    "    elif \"archive.\" in url:\n",
    "        return \"Archive\"\n",
    "    elif \"play.google.\" in url:\n",
    "        return \"GooglePlay\"\n",
    "    elif \"genius.\" in url:\n",
    "        return \"Genius\"\n",
    "    elif \"musicmoz.\" in url:\n",
    "        return \"Musicmoz\"\n",
    "    elif \"imvdb.\" in url:\n",
    "        return \"IMVBD\"\n",
    "    elif \"musik-sammler.\" in url:\n",
    "        return \"MusikSammler\"\n",
    "    elif \"whosampled.\" in url:\n",
    "        return \"WhoSampled\"\n",
    "    elif \"setlist.\" in url:\n",
    "        return \"SetListFM\"\n",
    "    elif \"secondhandsongs.\" in url:\n",
    "        return \"SecondhandSongs\"\n",
    "    elif \"apple.\" in url:\n",
    "        return \"Apple\"\n",
    "    elif \"deezer.\" in url:\n",
    "        return \"Deezer\"\n",
    "    elif \"twitter.\" in url:\n",
    "        return \"Twitter\"\n",
    "    elif \"songkick.\" in url:\n",
    "        return \"Songkick\"\n",
    "    elif \"instagram.\" in url:\n",
    "        return \"Instagram\"\n",
    "    elif \"tidal.\" in url:\n",
    "        return \"Tidal\"\n",
    "    elif \"bbc.\" in url:\n",
    "        return \"BBC\"\n",
    "    elif \"musixmatch.\" in url:\n",
    "        return \"MusixMatch\"\n",
    "    elif \"napster.\" in url:\n",
    "        return \"Napster\"\n",
    "    elif \"junodownload.\" in url:\n",
    "        return \"JunoDownload\"\n",
    "    elif \"beatport.\" in url:\n",
    "        return \"Beatport\"\n",
    "    elif \"bandsintown.\" in url:\n",
    "        return \"BandsInTown\"\n",
    "    elif \"bandcamp.\" in url:\n",
    "        return \"BandCamp\"\n",
    "    else:\n",
    "        return \"Misc\"\n",
    "\n",
    "def getURLType(urlGroupID):\n",
    "    urlGroupName = urlType.get(str(urlGroupID),\"Misc\")\n",
    "    return urlGroupName\n",
    "\n",
    "ts = Timestat(\"Getting URL Group Name\")\n",
    "lookupData['l_artist_url']['URLGroupName'] = lookupData['l_artist_url']['URL'].apply(getURLGroupName)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Dropping Last Columns\")\n",
    "lookupData['l_artist_url'].drop([\"NA6\", \"NA7\"], axis=1, inplace=True)\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(\"Grouping By ArtistID (~2 min)\")\n",
    "artistURLs = Series({artistID: list(zip(artistIDURLs[\"URLGroupName\"], artistIDURLs[\"URL\"])) for artistID,artistIDURLs in lookupData['l_artist_url'].groupby(\"ArtistID\")})\n",
    "ts.stop()\n",
    "\n",
    "savename = saveDir.join(\"ArtistURLDataFrame.p\")\n",
    "ts = Timestat(\"Saving Master Artist URL DataFrame To {0} (~11 sec)\".format(savename.str))\n",
    "io.save(idata=artistURLs, ifile=savename)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Artist Summary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw MDBIO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FileInfo, DirInfo, Timestat, FileIO\n",
    "from musicdb.musicbrainz import MusicDBIO\n",
    "mdbio = MusicDBIO(verbose=True, mod=False, mkDirs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Loading Master Data (~30 sec)\")\n",
    "artistDataFrameFile    = saveDir.join(\"ArtistDataFrame.p\")\n",
    "if not artistDataFrameFile.exists():\n",
    "    raise ValueError(f\"{artistDataFrameFile.str} doesn't exist\")\n",
    "masterArtistData       = io.get(artistDataFrameFile)\n",
    "if not isinstance(masterArtistData, DataFrame):\n",
    "    raise ValueError(\"Master Artist Data is not a DataFrame\")\n",
    "    \n",
    "artistURLDataFrameFile = saveDir.join(\"ArtistURLDataFrame.p\")\n",
    "if not artistURLDataFrameFile.exists():\n",
    "    raise ValueError(f\"{artistURLDataFrameFile.str} doesn't exist\")\n",
    "masterArtistURLData    = io.get(artistURLDataFrameFile)\n",
    "if not isinstance(masterArtistURLData, Series):\n",
    "    raise ValueError(\"Master Artist Data is not a DataFrame\")\n",
    "masterArtistURLData.name = \"URLs\"\n",
    "\n",
    "masterArtistData       = masterArtistData.join(masterArtistURLData)\n",
    "masterArtistData.index.name = \"mbidx\"\n",
    "masterArtistData.head()\n",
    "ts.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(f\"Saving {masterArtistData.shape[0]} Artists To Raw MB Data\")\n",
    "mdbio.rdio.getFilename(\"SearchArtist\")\n",
    "io.save(idata=masterArtistData, ifile=\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistDataFrame.post.p\")\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = io.get(ifile=\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistGTRDataFrame.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.save(idata=tmp, ifile=\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistGTRDataFrame.post.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from master import MasterParams, MusicDBPermDir\n",
    "from sys import prefix\n",
    "from pandas import Series, DataFrame, concat, Timestamp\n",
    "from base import MusicDBDir, MusicDBData\n",
    "from lib.musicbrainz import MusicDBIO\n",
    "artistIDs = artistData[\"ArtistName\"].copy(deep=True)\n",
    "artistIDs.index = artistData[\"ArtistGID\"]\n",
    "\n",
    "mdbio = MusicDBIO(verbose=True, mod=True, mkDirs=False)\n",
    "mdbpd = MusicDBPermDir()\n",
    "db    = mdbio.db\n",
    "permDBDir = mdbpd.getDBPermPath(db)\n",
    "permDir = MusicDBDir(permDBDir)\n",
    "allArtists = MusicDBData(path=permDir, fname=\"{0}AllArtists\".format(db.lower()))\n",
    "allArtists.save(data=artistIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterReleaseDataFile    = saveDir.join(\"ReleaseDataFrame.p\")\n",
    "if not masterReleaseDataFile.exists():\n",
    "    raise ValueError(f\"{masterReleaseDataFile.str} doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterReleaseData = io.get(masterReleaseDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = to_datetime(masterReleaseDataYearLang[\"Release\"], errors='coerce', format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import NaT\n",
    "s.map(lambda x: x.year if not NaT else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import to_datetime\n",
    "\n",
    "ts = Timestat(\"Getting ReleaseGroup Year/Language From Releases\")\n",
    "masterReleaseDataYearLang = DataFrame({releaseGroupID: (df[\"ReleaseDate\"].min(), df[\"Language\"].unique()) for releaseGroupID,df in masterReleaseData[[\"ReleaseGroupID\", \"Language\", \"ReleaseDate\"]].groupby(\"ReleaseGroupID\")}).T\n",
    "masterReleaseDataYearLang.columns = [\"Release\", \"Language\"]\n",
    "masterReleaseDataYearLang[\"Year\"] = to_datetime(masterReleaseDataYearLang[\"Release\"], errors='coerce', format=\"%Y%m%d\").map(lambda x: x.year)\n",
    "def getLang(lang):\n",
    "    retvals = [value for value in lang if value is not None]\n",
    "    retval  = retvals[0] if len(retvals) == 1 else None\n",
    "    return retval\n",
    "masterReleaseDataYearLang[\"Language\"] = masterReleaseDataYearLang[\"Language\"].apply(getLang)\n",
    "masterReleaseDataYearLang.index.name = \"ReleaseGroupID\"\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReleaseGroup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createReleaseGroupKey(x):\n",
    "    key = None\n",
    "    primary   = x['ReleaseGroupPrimaryType']\n",
    "    secondary = x['ReleaseGroupSecondaryType']\n",
    "    if isinstance(primary, str) and isinstance(secondary, str):\n",
    "        key = \" + \".join([primary, secondary])\n",
    "    elif isinstance(primary, str):\n",
    "        key = primary\n",
    "    elif isinstance(secondary, str):\n",
    "        key = secondary\n",
    "    else:\n",
    "        key = \"Unknown\"\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdbio = MusicDBIO(verbose=True, mod=False, mkDirs=False)\n",
    "tmp = io.get(\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistDataFrame.post.p\")\n",
    "ArtistIDtoGIDLookup = tmp[~tmp[\"ArtistGID\"].duplicated()][\"ArtistGID\"]\n",
    "io.save(idata=ArtistIDtoGIDLookup, ifile=saveDir.join(\"ArtistIDtoGIDLookup.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Loading Master Data (~30 sec)\")\n",
    "masterReleaseGroupDataFile    = saveDir.join(\"ReleaseGroupDataFrame.p\")\n",
    "if not masterReleaseGroupDataFile.exists():\n",
    "    raise ValueError(f\"masterReleaseGroupDataFile doesn't exist\")\n",
    "masterReleaseGroupData    = io.get(masterReleaseGroupDataFile)\n",
    "if not isinstance(masterReleaseGroupData, DataFrame):\n",
    "    raise ValueError(\"masterReleaseGroupData is not a DataFrame\")\n",
    "masterReleaseGroupData[\"ReleaseGroupKey\"] = masterReleaseGroupData.apply(createReleaseGroupKey, axis=1)\n",
    "\n",
    "ArtistIDtoGIDLookupFile       = saveDir.join(\"ArtistIDtoGIDLookup.p\")\n",
    "if not ArtistIDtoGIDLookupFile.exists():\n",
    "    raise ValueError(f\"ArtistIDtoGIDLookupFile doesn't exist\")\n",
    "ArtistIDtoGIDLookup       = io.get(ArtistIDtoGIDLookupFile)\n",
    "if not isinstance(ArtistIDtoGIDLookup, Series):\n",
    "    raise ValueError(\"ArtistIDtoGIDLookup is not a dict\")\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseGroupData = masterReleaseGroupData.join(masterReleaseDataYearLang)\n",
    "releaseGroupData[\"ArtistGID\"] = releaseGroupData[\"ArtistID\"].map(ArtistIDtoGIDLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Getting ReleaseGroup Data (~8 mins)\")\n",
    "artistReleaseGroupData = {}\n",
    "for i,(artistGID,artistData) in enumerate(releaseGroupData.groupby(\"ArtistGID\")):\n",
    "    artistReleaseGroupData[artistGID] = {str(idx): row.to_list() for idx,row in artistData[[\"ReleaseGroupName\", \"ReleaseGroupKey\", \"ReleaseGroupGID\", \"Language\", \"Year\"]].iterrows()}\n",
    "    if (i+1) % 250000 == 0 or (i+1) % 25000 == 0:\n",
    "        ts.update(n=i+1, cmt=f\"Processed {i+1} GIDs\")\n",
    "ts.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdbio.rdio.getFilename(\"SearchReleaseGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(f\"Saving {len(artistReleaseGroupData)} Artist ReleaseGroups To Raw MB Data\")\n",
    "io.save(idata=Series(artistReleaseGroupData), ifile=\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistReleaseGroupDataFrame.post.p\")\n",
    "# mdbio.data.saveSearchReleaseGroupData(data=Series(artistReleaseGroupData))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ArtistIDtoGIDLookupFile       = saveDir.join(\"ArtistIDtoGIDLookup.p\")\n",
    "if not ArtistIDtoGIDLookupFile.exists():\n",
    "    raise ValueError(f\"ArtistIDtoGIDLookupFile doesn't exist\")\n",
    "ArtistIDtoGIDLookup       = io.get(ArtistIDtoGIDLookupFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ArtistIDtoGIDLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Loading Master Data (~30 sec)\")\n",
    "masterWorkDataFile    = saveDir.join(\"ArtistWorkDataFrame.p\")\n",
    "if not masterWorkDataFile.exists():\n",
    "    raise ValueError(f\"{masterWorkDataFile.str} doesn't exist\")\n",
    "masterArtistWorkData    = io.get(masterWorkDataFile)\n",
    "if not isinstance(masterArtistWorkData, Series):\n",
    "    raise ValueError(\"masterWorkData is not a Series\")\n",
    "\n",
    "ArtistIDtoGIDLookupFile       = saveDir.join(\"ArtistIDtoGIDLookup.p\")\n",
    "if not ArtistIDtoGIDLookupFile.exists():\n",
    "    raise ValueError(f\"ArtistIDtoGIDLookupFile doesn't exist\")\n",
    "ArtistIDtoGIDLookup       = io.get(ArtistIDtoGIDLookupFile)\n",
    "if not isinstance(ArtistIDtoGIDLookup, Series):\n",
    "    raise ValueError(\"ArtistIDtoGIDLookup is not a dict\")\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdbio.data.saveSearchWorkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Timestat(\"Grouping Work Data\")\n",
    "artistWorkData = {ArtistIDtoGIDLookup.get(artistID): artistIDData for artistID,artistIDData in masterArtistWorkData.items()}\n",
    "artistWorkData = Series({k: v for k,v in artistWorkData.items() if all([x is not None for x in [k,v]])})\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(f\"Saving {len(artistWorkData)} Artist Work To Raw MB Data\")\n",
    "io.save(idata=artistWorkData, ifile=\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistWorkDataFrame.post.p\")\n",
    "\n",
    "#mdbio.data.saveSearchWorkData(data=Series(artistWorkData))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Recording Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = Timestat(\"Loading Master Data (~30 sec)\")\n",
    "masterRecordingDataFile    = saveDir.join(\"ArtistRecordingDataFrame.p\")\n",
    "if not masterRecordingDataFile.exists():\n",
    "    raise ValueError(f\"{masterRecordingDataFile.str} doesn't exist\")\n",
    "masterArtistRecordingData    = io.get(masterRecordingDataFile)\n",
    "if not isinstance(masterArtistRecordingData, Series):\n",
    "    raise ValueError(\"masterRecordingData is not a Series\")\n",
    "\n",
    "ArtistIDtoGIDLookupFile       = saveDir.join(\"ArtistIDtoGIDLookup.p\")\n",
    "if not ArtistIDtoGIDLookupFile.exists():\n",
    "    raise ValueError(f\"ArtistIDtoGIDLookupFile doesn't exist\")\n",
    "ArtistIDtoGIDLookup       = io.get(ArtistIDtoGIDLookupFile)\n",
    "if not isinstance(ArtistIDtoGIDLookup, Series):\n",
    "    raise ValueError(\"ArtistIDtoGIDLookup is not a dict\")\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = Timestat(\"Grouping Recording Data\")\n",
    "artistRecordingData = {ArtistIDtoGIDLookup.get(artistID): artistIDData for artistID,artistIDData in masterArtistRecordingData.items()}\n",
    "artistRecordingData = Series({k: v for k,v in artistRecordingData.items() if all([x is not None for x in [k,v]])})\n",
    "ts.stop()\n",
    "\n",
    "ts = Timestat(f\"Saving {len(artistRecordingData)} Artist Recording To Raw MB Data\")\n",
    "io.save(idata=artistRecordingData, ifile=\"/Volumes/Piggy/Discog/artists-musicbrainz/search/ArtistRecordingDataFrame.post.p\")\n",
    "# mdbio.data.saveRawRecordingMBData(data=Series(artistRecordingData))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterArtistRecordingData.name = \"Recording\"\n",
    "masterArtistRecordingData.index.name = \"ArtistID\"\n",
    "masterArtistRecordingData.reset_index()\n",
    "masterArtistRecordingData[\"ArtistGID\"] = masterArtistRecordingData[\"ArtistID\"].apply(artistIDtoGIDLookup.get)\n",
    "saveData = {artistGID: df[\"Recording\"] for artistGID,df in masterArtistRecordingData.groupby(\"ArtistGID\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "releaseGroupData['ArtistID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ts = Timestat(\"Getting Release Group Data\")\n",
    "for artistID,df in masterReleaseGroupData[[\"ArtistID\", \"ReleaseGroupName\", \"ReleaseGroupKey\", \"ReleaseGroupGID\"]].groupby(\"ArtistID\"):\n",
    "    print(artistID)\n",
    "    print(df)\n",
    "    break\n",
    "#ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterArtistURLData.name = \"URLs\"\n",
    "masterArtistData = masterArtistData.join(masterArtistURLData)\n",
    "masterArtistData.index.name = \"mbidx\"\n",
    "print(\"Saving Artist DataFrame With {0} Entries To {1}\".format(masterArtistData.shape[0], mio.data.getSearchArtistFilename().str))\n",
    "mio.data.saveSearchArtistData(data=masterArtistData)\n",
    "ts.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "ts = timestat(\"Setting ReleaseGroup Key (~1/2 min)\")\n",
    "masterReleaseGroupData[\"ReleaseGroupKey\"] = masterReleaseGroupData.apply(createReleaseGroupKey, axis=1)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterReleaseGroupData    = io.get(savedir.join(\"{0}.p\".format(\"ReleaseGroupDataFrame\")).path)\n",
    "masterArtistRecordingData = io.get(savedir.join(\"{0}.p\".format(\"ArtistRecordingDataFrame\")).path)\n",
    "masterArtistWorkData      = io.get(savedir.join(\"{0}.p\".format(\"ArtistWorkDataFrame\")).path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Artist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from parseRawDataBase import parseRawDataBase\n",
    "from timeUtils import timestat\n",
    "from fsUtils import fsInfo\n",
    "from pandas import Series\n",
    "\n",
    "        \n",
    "class parseRawMusicBrainzData(parseRawDataBase):\n",
    "    def __init__(self, verbose=True):\n",
    "        super().__init__(db=\"MusicBrainz\", verbose=verbose)\n",
    "        self.rms = []\n",
    "        \n",
    "    \n",
    "    def parseArtistData(self, masterArtistData):\n",
    "        if self.verbose: ts = timestat(\"Parsing Raw {0} Data(masterArtistData)\".format(self.db))\n",
    "\n",
    "        for modVal,artistModValData in masterArtistData.groupby(\"ModVal\"):\n",
    "            modValData = {}\n",
    "            N = artistModValData.shape[0]\n",
    "            if self.verbose: tsParse = timestat(\"Parsing {0} ModVal={1} Entries\".format(modVal, N))\n",
    "            pModVal = self.utils.getPrintModValue(N)\n",
    "            for i,(artistMBID,artistData) in enumerate(artistModValData.iterrows()):\n",
    "                rData = self.dbIO.rawIO.getArtistData(artistData)\n",
    "                artistID = rData.ID.ID\n",
    "                if artistID is None:\n",
    "                    continue\n",
    "                modValData[artistID] = rData\n",
    "\n",
    "            if self.verbose: print(\"Saving [{0}] Artist {1} Entries\".format(len(modValData), \"DB Data\"))\n",
    "            self.dbIO.saveArtistModValData(modVal, modValData)\n",
    "            \n",
    "        if self.verbose: ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from dbIOGate import dbIOGate\n",
    "from dbMusicBrainzIO import dbMusicBrainzIO\n",
    "gate = dbIOGate()\n",
    "gate.get(\"MusicBrainz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prd = parseRawMusicBrainzData()\n",
    "prd.parseArtistData(masterArtistData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    ##########################################################################################\n",
    "    # DB ModVal Data Utils\n",
    "    ##########################################################################################\n",
    "    def getParseArtistModValDictData(self, modVal, force=False):\n",
    "        modValData = {} if force is True else self.dbIO.getArtistModValData(modVal)\n",
    "        #modValData = modValData.to_dict() if isinstance(modValData,Series) else {}\n",
    "        return modValData\n",
    "    \n",
    "    def saveParseArtistModValDictData(self, modVal, modValData):\n",
    "        #modValData = Series(modValData) if isinstance(modValData,dict) else modValData\n",
    "        self.dbIO.saveArtistModValData(modVal, modValData)\n",
    "        \n",
    "    def getParseReleaseModValDictData(self, modVal, force=False):\n",
    "        modValData = {} if force is True else self.dbIO.getReleaseModValData(modVal)\n",
    "        #modValData = modValData.to_dict() if isinstance(modValData,Series) else {}\n",
    "        return modValData\n",
    "    \n",
    "    def saveParseReleaseModValDictData(self, modVal, modValData):\n",
    "        #modValData = Series(modValData) if isinstance(modValData,dict) else modValData\n",
    "        self.dbIO.saveReleaseModValData(modVal, modValData)\n",
    "        \n",
    "    def getParseWorkModValDictData(self, modVal, force=False):\n",
    "        modValData = {} if force is True else self.dbIO.getWorkModValData(modVal)\n",
    "        #modValData = modValData.to_dict() if isinstance(modValData,Series) else {}\n",
    "        return modValData\n",
    "    \n",
    "    def saveParseWorkModValDictData(self, modVal, modValData):\n",
    "        #modValData = Series(modValData) if isinstance(modValData,dict) else modValData\n",
    "        self.dbIO.saveWorkModValData(modVal, modValData)\n",
    "        \n",
    "    def getParseRecordingModValDictData(self, modVal, force=False):\n",
    "        modValData = {} if force is True else self.dbIO.getRecordingModValData(modVal)\n",
    "        #modValData = modValData.to_dict() if isinstance(modValData,Series) else {}\n",
    "        return modValData\n",
    "    \n",
    "    def saveParseRecordingModValDictData(self, modVal, modValData):\n",
    "        #modValData = Series(modValData) if isinstance(modValData,dict) else modValData\n",
    "        self.dbIO.saveRecordingModValData(modVal, modValData)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #####################################################################################################################\n",
    "    # Parse Raw Data\n",
    "    #####################################################################################################################\n",
    "    def parseArtistData(self, modVal, expr='< 0 Days', force=False):\n",
    "        self.parseData(modVal, \"Artist\", expr, force)\n",
    "    def parseReleaseData(self, modVal, expr='< 0 Days', force=False):\n",
    "        self.parseData(modVal, \"Release\", expr, force)\n",
    "    def parseWorkData(self, modVal, expr='< 0 Days', force=False):\n",
    "        self.parseData(modVal, \"Work\", expr, force)\n",
    "    def parseRecordingData(self, modVal, expr='< 0 Days', force=False):\n",
    "        self.parseData(modVal, \"Recording\", expr, force)\n",
    "    def parse(self, modVal, expr='< 0 Days', force=False):\n",
    "        self.parseArtistData(modVal, expr, force)\n",
    "        self.parseReleaseData(modVal, expr, force)\n",
    "        self.parseWorkData(modVal, expr, force)\n",
    "        self.parseRecordingData(modVal, expr, force)\n",
    "        \n",
    "            \n",
    "    def mergeMediaData(self, prevMediaData, newMediaData):\n",
    "        for mediaType,mediaTypeData in newMediaData.items():\n",
    "            mtd  = {release.code: release for release in mediaTypeData}\n",
    "            pmtd = {release.code: release for release in prevMediaData.get(mediaType,[])}\n",
    "            pmtd.update(mtd)\n",
    "            prevMediaData[mediaType] = list(pmtd.values())\n",
    "            \n",
    "    def updateMediaCounts(self, artistIDData):\n",
    "        counts = {mediaType: len(mediaTypeData) for mediaType,mediaTypeData in artistIDData.media.media.items()}\n",
    "        artistIDData.mediaCounts = self.dbIO.rawIO.makeRawMediaCountsData(counts)\n",
    "    \n",
    "                            \n",
    "    def createModValData(self, modVal):\n",
    "        if self.verbose: ts = timestat(\"Creating ModValData From Parsed Raw ModVal={0} Data\".format(modVal))\n",
    "            \n",
    "        parseArtistModValData      = self.getParseArtistModValDictData(modVal)\n",
    "        parseReleaseModValData      = self.getParseReleaseModValDictData(modVal)\n",
    "        parseWorkModValData        = self.getParseWorkModValDictData(modVal)\n",
    "        parseRecordingModValData = self.getParseRecordingModValDictData(modVal)\n",
    "\n",
    "        modValData = {}\n",
    "        for parseModValData in [parseArtistModValData, parseReleaseModValData, parseWorkModValData, parseRecordingModValData]:\n",
    "            for artistID,artistIDData in parseModValData.items():\n",
    "                if artistID is None:\n",
    "                    continue\n",
    "                if modValData.get(artistID) is None:\n",
    "                    modValData[artistID] = artistIDData\n",
    "                else:\n",
    "                    self.mergeMediaData(modValData[artistID].media.media, artistIDData.media.media)\n",
    "                    self.updateMediaCounts(modValData[artistID])\n",
    "                        \n",
    "                        \n",
    "        if self.verbose: print(\"Saving [{0}] ModVal={1} {2} Entries\".format(len(modValData), modVal, \"DB Data\"))\n",
    "        self.utils.saveModValData(modVal, modValData)\n",
    "        if self.verbose: ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = timestat(\"Creating Artist Data\")\n",
    "rawIO = rawMusicBrainzDataIO()\n",
    "for modVal,artistModValData in masterArtistData.groupby(\"ModVal\"):\n",
    "    modValData = {}\n",
    "    N = artistModValData.shape[0]\n",
    "    tsMod = timestat(\"Creating DB Data From {0} Artists For ModVal={1}\".format(N,modVal))\n",
    "    for i,(artistMBID,artistData) in enumerate(artistModValData.iterrows()):\n",
    "        rData = rawIO.getArtistData(artistData)\n",
    "        artistID = rData.ID.ID\n",
    "        if artistID is None:\n",
    "            continue\n",
    "        modValData[artistID] = rData\n",
    "    dbIO.saveArtistModValData(modVal, modValData)        \n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterReleaseGroupData    = io.get(savedir.join(\"{0}.p\".format(\"ReleaseGroupDataFrame\")).path)\n",
    "masterArtistRecordingData = io.get(savedir.join(\"{0}.p\".format(\"ArtistRecordingDataFrame\")).path)\n",
    "masterArtistWorkData      = io.get(savedir.join(\"{0}.p\".format(\"ArtistWorkDataFrame\")).path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "savedir = setDir(basedir, \"MusicBrainzMetadata\")\n",
    "tsAll = timestat(\"Creating DB Data\")\n",
    "Nmod = 100\n",
    "for n,modVal in enumerate(range(Nmod)):\n",
    "    ts = timestat(\"Creating ModData Subset\")\n",
    "    artistModData = masterArtistData[masterArtistData[\"MyArtistID\"].apply(lambda x: int(x)%Nmod) == modVal]\n",
    "    releaseGroupModData = masterReleaseGroupData[masterReleaseGroupData[\"ArtistID\"].isin(artistModData.index)]\n",
    "    ts.stop()\n",
    "\n",
    "    modValData = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from artistDBBase import artistDBBase, artistDBDataClass\n",
    "from artistDBBase import artistDBNameClass, artistDBMetaClass, artistDBIDClass, artistDBURLClass, artistDBPageClass\n",
    "from artistDBBase import artistDBProfileClass, artistDBMediaClass, artistDBMediaAlbumClass\n",
    "from artistDBBase import artistDBMediaDataClass, artistDBMediaCountsClass, artistDBFileInfoClass\n",
    "from artistDBBase import artistDBTextClass, artistDBLinkClass\n",
    "from strUtils import fixName\n",
    "from dbUtils import utilsDiscogs\n",
    "from hashlib import md5\n",
    "\n",
    "def getMediaCounts(media):\n",
    "    amcc = artistDBMediaCountsClass()\n",
    "\n",
    "    credittype = \"Releases\"\n",
    "    if amcc.counts.get(credittype) == None:\n",
    "        amcc.counts[credittype] = {}\n",
    "    for creditsubtype in media.media.keys():\n",
    "        amcc.counts[credittype][creditsubtype] = int(len(media.media[creditsubtype]))\n",
    "\n",
    "    return amcc\n",
    "\n",
    "savedir = setDir(basedir, \"MusicBrainzMetadata\")\n",
    "tsAll = timestat(\"Creating DB Data\")\n",
    "Nmod = 100\n",
    "for n,modVal in enumerate(range(Nmod)):\n",
    "    ts = timestat(\"Creating ModData Subset\")\n",
    "    artistModData = masterArtistData[masterArtistData[\"MyArtistID\"].apply(lambda x: int(x)%Nmod) == modVal]\n",
    "    releaseGroupModData = masterReleaseGroupData[masterReleaseGroupData[\"ArtistID\"].isin(artistModData.index)]\n",
    "    ts.stop()\n",
    "\n",
    "    modValData = {}\n",
    "    N = artistModData.shape[0]\n",
    "    tsMod = timestat(\"Creating DB Data From {0} Artists For ModVal={1}\".format(N,modVal))\n",
    "    for i,(artistID,artistData) in enumerate(artistModData.iterrows()):\n",
    "        artistName  = str(artistData[\"ArtistName\"])\n",
    "        artistGID   = artistData['ArtistGID']\n",
    "        artistURL   = \"https://musicbrainz.org/artist/{0}\".format(artistGID)\n",
    "        myID        = artistData[\"MyArtistID\"]\n",
    "        #if artistGID != \"070d193a-845c-479f-980e-bef15710653e\":\n",
    "        #    continue\n",
    "        #if myID != '251108434349887660386335524263902329399':\n",
    "        #    continue\n",
    "\n",
    "        generalData = {}\n",
    "        generalData[\"SortName\"]   = artistData[\"ArtistSortName\"]\n",
    "        generalData[\"Aliases\"]    = artistData[\"Aliases\"]\n",
    "        generalData[\"Gender\"]     = artistData[\"Gender\"]\n",
    "        generalData[\"County\"]     = artistData[\"Country\"]\n",
    "        generalData[\"Formed\"]     = artistData[\"Formed\"]\n",
    "        generalData[\"Disbanded\"]  = artistData[\"Disbanded\"]\n",
    "        generalData[\"ArtistType\"] = artistData[\"ArtistType\"]\n",
    "        generalData[\"ISNI\"]       = artistData[\"ISNICode\"]\n",
    "        generalData = {k: v for k,v in generalData.items() if v is not None}\n",
    "        generalData = generalData if len(generalData) > 0 else None\n",
    "\n",
    "        \n",
    "        ########################################################################\n",
    "        # Get URLs\n",
    "        ########################################################################\n",
    "        externalData = {}\n",
    "        artistURLs = masterArtistURLData.get(artistID, [])\n",
    "        for (urlType,url) in artistURLs:\n",
    "            adblink      = artistDBLinkClass(None)\n",
    "            adblink.href = url\n",
    "            adblink.err  = None\n",
    "            if externalData.get(urlType) is None:\n",
    "                externalData[urlType] = []\n",
    "            externalData[urlType].append(adblink)\n",
    "        externalData = externalData if len(externalData) > 0 else None\n",
    "        \n",
    "            \n",
    "        \n",
    "        ########################################################################\n",
    "        # Get Release Groups\n",
    "        ########################################################################\n",
    "        artistReleaseGroupData = releaseGroupModData[releaseGroupModData[\"ArtistID\"] == artistID]\n",
    "        mediaData = {}\n",
    "        for mediaName,mediaNameData in artistReleaseGroupData.groupby(\"ReleaseGroupKey\"):\n",
    "            mediaData[mediaName] = []\n",
    "            for code, releaseGroupInfo in mediaNameData.iterrows():\n",
    "                album        = releaseGroupInfo['ReleaseGroupName']\n",
    "                albumURL     = \"https://musicbrainz.org/releasegroup/{0}\".format(releaseGroupInfo['ReleaseGroupGID'])\n",
    "                albumArtists = [artistName]\n",
    "            \n",
    "                amdc = artistDBMediaDataClass(album=album, url=albumURL, artist=albumArtists, code=code, year=None)\n",
    "                mediaData[mediaName].append(amdc)\n",
    "                \n",
    "            \n",
    "        ########################################################################\n",
    "        # Get Works\n",
    "        ########################################################################\n",
    "        artistWorks = masterArtistWorkData.get(artistID)  \n",
    "        if artistWorks:\n",
    "            for workID,workType,workName in artistWorks:\n",
    "                mediaName = \"OtherWork\" if workType is None else workType\n",
    "                if mediaData.get(mediaName) is None:\n",
    "                    mediaData[mediaName] = []\n",
    "                m = md5()\n",
    "                codes = {}\n",
    "                m.update(str(workID).encode('utf-8'))\n",
    "                m.update(str(mediaName).encode('utf-8'))\n",
    "                m.update(str(workName).encode('utf-8'))\n",
    "                hashval = m.hexdigest()\n",
    "                code    = str(int(hashval, 16) % int(1e6))\n",
    "                if codes.get(code) is not None:\n",
    "                    continue\n",
    "                codes[code] = True\n",
    "\n",
    "                amdc = artistDBMediaDataClass(album=str(workName), url=None, artist=None, code=code, year=None)\n",
    "                mediaData[mediaName].append(amdc)\n",
    "                \n",
    "            \n",
    "        ########################################################################\n",
    "        # Get Recordings\n",
    "        ########################################################################\n",
    "        artistRecordings = masterArtistRecordingData.get(artistID)        \n",
    "        artistRecordings = Series(artistRecordings).drop_duplicates()\n",
    "        if len(artistRecordings) > 0:\n",
    "            mediaName = \"Recordings\"\n",
    "            if mediaData.get(mediaName) is None:\n",
    "                mediaData[mediaName] = []\n",
    "            codes = {}\n",
    "            for idx,(recName,recTime) in artistRecordings.iteritems():\n",
    "                m = md5()\n",
    "                m.update(str(recName).encode('utf-8'))\n",
    "                m.update(str(recTime).encode('utf-8'))\n",
    "                hashval = m.hexdigest()\n",
    "                code    = str(int(hashval, 16) % int(1e6))\n",
    "                if codes.get(code) is not None:\n",
    "                    continue\n",
    "                codes[code] = True\n",
    "                \n",
    "                amdc = artistDBMediaDataClass(album=str(recName), url=None, artist=None, code=code, year=None)\n",
    "                mediaData[mediaName].append(amdc)\n",
    "\n",
    "        \n",
    "        artist      = artistDBNameClass(name=artistName, err=None)\n",
    "        meta        = artistDBMetaClass(title=None, url=artistURL)\n",
    "        url         = artistDBURLClass(url=artistURL)\n",
    "        ID          = artistDBIDClass(ID=myID)\n",
    "        pages       = artistDBPageClass(ppp=1, tot=1, redo=False, more=False)\n",
    "        profile     = artistDBProfileClass(general=generalData, external=externalData)\n",
    "        media       = artistDBMediaClass()\n",
    "        media.media = mediaData\n",
    "        mediaCounts = getMediaCounts(media)\n",
    "        info        = artistDBFileInfoClass(info=None)\n",
    "        \n",
    "        modValData[myID] = artistDBDataClass(artist=artist, meta=meta, url=url, ID=ID, pages=pages, profile=profile, mediaCounts=mediaCounts, media=media, info=info)\n",
    "        if (i+1) % 7500 == 0 or (i+1) == 2500:\n",
    "            tsMod.update(n=i+1, N=N)\n",
    "    tsMod.stop()\n",
    "            \n",
    "    outdir = setDir(basedir, \"MusicBrainzDBData\")\n",
    "    io.save(idata=Series(modValData), ifile=setFile(outdir, \"{0}-{1}.p\".format(modVal, \"DB\")))\n",
    "    tsAll.update(n=n, N=Nmod)\n",
    "    print(\"\\n\")\n",
    "tsAll.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modValData['108541848016828757278131944962756872900'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modValData['251108434349887660386335524263902329399'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Merge With Known DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = timestat(\"Merging DBs\")\n",
    "for n,modVal in enumerate(range(100)):\n",
    "    newDB = Series(io.get(\"/Volumes/Seagate/DB/MusicBrainzDBData/{0}-DB.p\".format(modVal)))\n",
    "    known = io.get(\"/Users/tgadfort/dbdiscogs/artists-musicbrainz-db/{0}-DB.p\".format(modVal))\n",
    "    \n",
    "    toMerge = newDB[~newDB.index.isin(known.index)]\n",
    "    fullDB = concat([known,toMerge]).sort_index()\n",
    "    io.save(idata=fullDB, ifile=\"/Users/tgadfort/dbdiscogs/artists-musicbrainz-db/full/{0}-DB.p\".format(modVal))\n",
    "    ts.update(n=n+1,N=100)\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "known.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp['172552485256597266680385033568580864600'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterArtistData = artistData['artist'][[\"ArtistGID\", \"ArtistName\", \"ArtistSortName\", \"Formed\", \"Disbanded\"]].copy(deep=True)\n",
    "masterArtistNumAlbums = artistIDNumReleaseGroups.join(artistIDNumRelease, how='outer')\n",
    "masterArtistData = masterArtistData.join(masterArtistNumAlbums)\n",
    "masterArtistData[\"NumReleaseGroups\"] = masterArtistData[\"NumReleaseGroups\"].fillna(0).apply(int)\n",
    "masterArtistData[\"NumReleases\"] = masterArtistData[\"NumReleases\"].fillna(0).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterArtistData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "masterartistNumAlbums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistIDNumReleaseGroups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistIDNumRelease.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistID'] == aIDs[\"ArianaGrande\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistID'] == aIDs[\"BuddyHolly\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistID'] == aIDs[\"Bono\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistID'] == aIDs[\"Rupaul\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistID'] == aIDs[\"U2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistID'] == aIDs[\"DMB\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][\"NA18\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][\"NA9\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist']['NA12'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist']['NA5'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist'][artistData['artist']['ArtistGID'] == '7f347782-eb14-40c3-98e2-17b6e1bfe56c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData[\"artist\"][artistData[\"artist\"][\"ArtistID\"] == 502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData[\"artist\"]['NA10'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData[\"artist\"][artistData[\"artist\"][\"ArtistID\"] == 197]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Artist Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames[\"l_artist_url\"]={0: \"ArtistURLLID\", 1: \"URLGroupID\", 2: \"ArtistID\", 3: \"URLID\"}\n",
    "colnames[\"l_artist_release_group\"]={0: \"ArtistReleaseGroupLID\", 1: \"ReleaseGroupGroupID\", 2: \"ArtistID\", 3: \"ReleaseGroupID\"}\n",
    "colnames[\"l_artist_release\"]={0: \"ArtistReleaseLID\", 1: \"ReleaseGroupID\", 2: \"ArtistID\", 3: \"ReleaseID\"}\n",
    "\n",
    "ts = timestat(\"Loading Artist Data\")\n",
    "files = glob(\"mbdump/l_artist_*\")\n",
    "lookupData = {fileInfo(ifile).basename: loadData(ifile) for ifile in files}\n",
    "lookupData = {key: val[list(colnames[key].keys())].rename(columns=colnames[key]) for key,val in lookupData.items() if key in colnames} if lookupData is not None else lookupData\n",
    "print(\"Keys: {0}\".format(lookupData.keys()))\n",
    "ts.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = glob(\"mbdump/l_artist_release\")\n",
    "lookupData = {fileInfo(ifile).basename: loadData(ifile) for ifile in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData['l_artist_release'][\"ReleaseGroupID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData['l_artist_release'][lookupData['l_artist_release']['ArtistID'] == 502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key='l_artist_url'\n",
    "lookupData['l_artist_url'] = lookupData['l_artist_url'][list(colnames[key].keys())].rename(columns=colnames[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(urlData['url'][urlData['url'][\"URLName\"].eq(\"https://www.discogs.com/artist/6520\")])\n",
    "print(urlData['url'][urlData['url'][\"URLName\"].eq(\"https://www.allmusic.com/artist/mn0000219203\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData[\"l_artist_url\"][lookupData[\"l_artist_url\"][\"URLID\"].isin([3017,993955])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas import merge\n",
    "dmbAU = lookupData[\"l_artist_url\"][lookupData[\"l_artist_url\"]['ArtistID'] == 502].copy(deep=True)\n",
    "u2AU  = lookupData[\"l_artist_url\"][lookupData[\"l_artist_url\"]['ArtistID'] == 197].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dmbURLs = merge(dmbAU, urlData['url'], how='left', on=[\"URLID\"]).copy(deep=True)\n",
    "u2URLs  = merge(u2AU, urlData['url'], how='left', on=[\"URLID\"]).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dmbURLs[\"URLDomain\"] = dmbURLs[\"URLName\"].apply(lambda x: x.replace(\"https://\", \"\").replace(\"http://\", \"\").split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u2URLs[\"URLDomain\"] = u2URLs[\"URLName\"].apply(lambda x: x.replace(\"https://\", \"\").replace(\"http://\", \"\").split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u2URLs[[\"NA1\", \"URLDomain\"]].sort_values(by=\"NA1\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dmbURLs[[\"NA1\", \"URLDomain\"]].sort_values(by=\"NA1\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData[\"artist\"][artistData[\"artist\"].eq(8723).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "urlData['url'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData[\"l_artist_url\"][lookupData[\"l_artist_url\"].eq(1025971).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData[\"l_artist_url\"][lookupData[\"l_artist_url\"].eq(2625).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lookupData[\"l_artist_url\"][lookupData[\"l_artist_url\"][2].eq(502).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DMB={AllMusic = 1025971 (c94225e3-2f0c-4c6d-9115-9f268fb7c31b), Discogs = 2625 (7a157b6e-d01d-4248-9995-edb05652c5b2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "artistData['artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colnames = {0: \"ArtistID\", 1: \"NA1\", 2: \"NA2\": 3: \"NA3\"}\n",
    "lookupData[\"l_artist_artist\"][lookupData[\"l_artist_artist\"].eq(502).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "urlData['url'][urlData['url'][\"URLName\"].eq(\"https://www.discogs.com/artist/6520\")]\n",
    "urlData['url'][urlData['url'][\"URLName\"].eq(\"https://www.allmusic.com/artist/mn0000219203\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "502\n",
    "07e748f1-075e-428d-85dc-ce3be434e906"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
